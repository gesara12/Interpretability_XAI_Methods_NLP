{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS6sOPFpXQPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cfb07e-a5c3-4228-e612-a10284a591ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "XS6sOPFpXQPD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AeBIjcLXsHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeb598e6-10f9-4d8c-de9e-b2bac7d7959b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 35.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 41.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 46.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 40.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 275 kB 32.0 MB/s \n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q lime"
      ],
      "id": "-AeBIjcLXsHE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f5d1ba3-a6da-4c4a-8563-8153610873c2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.models import load_model\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "id": "7f5d1ba3-a6da-4c4a-8563-8153610873c2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eca0c98-8245-4387-b9f1-de95e52bbcbd"
      },
      "outputs": [],
      "source": [
        "model_lstm = load_model('/content/drive/MyDrive/MasterThesis/LSTM/lstm.h5')"
      ],
      "id": "6eca0c98-8245-4387-b9f1-de95e52bbcbd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0446a16-409e-46d6-bbad-e013943fa445"
      },
      "outputs": [],
      "source": [
        "test_x =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_test_all.csv')\n",
        "train_x =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_train_all.csv')\n",
        "test_sentences = test_x.clean_review.astype(str)\n",
        "train_sentences = train_x.clean_review.astype(str)"
      ],
      "id": "f0446a16-409e-46d6-bbad-e013943fa445"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a449fb6-4f70-4b6e-8232-1082351f214a"
      },
      "outputs": [],
      "source": [
        "max_features = 90166\n",
        "max_length = 50\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train_sentences)"
      ],
      "id": "1a449fb6-4f70-4b6e-8232-1082351f214a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f77ee851-9797-4912-ae46-09386769dcc1"
      },
      "outputs": [],
      "source": [
        "explainer = LimeTextExplainer(class_names=[\"Negative\", \"Positive\"])"
      ],
      "id": "f77ee851-9797-4912-ae46-09386769dcc1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a839b4e-25a4-47a7-a660-dda6b00fde99"
      },
      "outputs": [],
      "source": [
        "#As the test_data is already an array of embeddings we can wrap the predict function into a function that takes in a list of strings and returns prediction probabilities\n",
        "\n",
        "def new_predict(texts):\n",
        "    _seq = tokenizer.texts_to_sequences(texts)\n",
        "    _text_data = pad_sequences(\n",
        "        _seq, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
        "    )\n",
        "    return np.array([[float(1 - x), float(x)] for x in model_lstm.predict(_text_data)])"
      ],
      "id": "1a839b4e-25a4-47a7-a660-dda6b00fde99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b5d3729-50c2-4851-ac84-2ac86c8ced2b"
      },
      "outputs": [],
      "source": [
        "#{845, 1556, 1750, 2150, 2514, 2631, 2652, 2845, 3354, 3447, 3929}\n",
        "idx = 2047 \n",
        "exp = explainer.explain_instance(test_sentences.iloc[idx], new_predict, num_features=50)\n",
        "#exp.show_in_notebook()"
      ],
      "id": "7b5d3729-50c2-4851-ac84-2ac86c8ced2b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74ghV1_AgZ7n"
      },
      "outputs": [],
      "source": [
        "exp_list = exp.as_list()\n",
        "#sorted(exp_list, key=lambda x: x[1])"
      ],
      "id": "74ghV1_AgZ7n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample calculation**\n",
        "\n",
        "Calculating and saving feature importance score for the reviews used as a demonstration example to measure the proposed criteria."
      ],
      "metadata": {
        "id": "UhUdddqOhDEc"
      },
      "id": "UhUdddqOhDEc"
    },
    {
      "cell_type": "code",
      "source": [
        "pos_sample = pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/positive_sample_50', 'rb'))\n",
        "neg_sample = pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/negative_sample_50', 'rb')) "
      ],
      "metadata": {
        "id": "w1lpMDK2hhQ9"
      },
      "id": "w1lpMDK2hhQ9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lime_calc(sample):\n",
        "  lime_calc = []\n",
        "  for i in sample:\n",
        "    exp = explainer.explain_instance(test_sentences.iloc[i], new_predict, num_features=50) \n",
        "    exp_list = exp.as_list()\n",
        "    sorted_list = sorted(exp_list, key=lambda x: x[1])\n",
        "    lime_calc.append(sorted_list)\n",
        "  return lime_calc"
      ],
      "metadata": {
        "id": "g0EZi4LPhCOb"
      },
      "id": "g0EZi4LPhCOb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = lime_calc(pos_sample)\n",
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/lime_lstm_positive_sample_50', 'wb') as f:\n",
        "    pickle.dump(r, f) \n",
        "\n",
        "r = lime_calc(neg_sample)\n",
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/lime_lstm_negative_sample_50', 'wb') as f:\n",
        "    pickle.dump(r, f)        "
      ],
      "metadata": {
        "id": "IbpQIGFphCQ4"
      },
      "id": "IbpQIGFphCQ4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "lstm_LIME.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}