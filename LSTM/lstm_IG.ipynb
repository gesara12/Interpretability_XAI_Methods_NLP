{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o223y7E2UNI",
        "outputId": "7cd76cda-cd2e-42d2-adc6-8c7d6c412ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUG4sS8Q2Wtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f28c1f7-c412-4507-f872-7f10155f62db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 397 kB 14.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 28.0 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 49.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.4 MB/s \n",
            "\u001b[?25h  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q alibi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaAoDomW0IFw",
        "outputId": "95946265-2fc9-418a-e3af-0ea5fa8cb7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eager execution enabled:  True\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from alibi.explainers import IntegratedGradients\n",
        "print('Eager execution enabled: ', tf.executing_eagerly()) # True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNaZnAke0IFz"
      },
      "outputs": [],
      "source": [
        "train_x = pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_train_all.csv')\n",
        "test_x =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_test_all.csv')\n",
        "\n",
        "train_y = pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/y_train_all.csv')\n",
        "test_y =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/y_test_all.csv')\n",
        "\n",
        "y_test = test_y.rate\n",
        "y_train = train_y.rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33fi0YXt2bwG"
      },
      "outputs": [],
      "source": [
        "train_sentences = train_x.clean_review.values.astype(str)\n",
        "test_sentences = test_x.clean_review.values.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RySYPCrz0IF0"
      },
      "outputs": [],
      "source": [
        "max_features = 90166\n",
        "max_length = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPMllC6q0IF0"
      },
      "outputs": [],
      "source": [
        "model_lstm = load_model('/content/drive/MyDrive/MasterThesis/LSTM/lstm.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H15Ygdl72tf-"
      },
      "outputs": [],
      "source": [
        "def decode_sentence(x, reverse_index):\n",
        "    return \" \".join([reverse_index.get(i, 'UNK') for i in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvtzbV7z0IF1"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/word_index', 'rb') as f:\n",
        "    word_index = pickle.load(f)\n",
        "reverse_index = {value: key for (key, value) in word_index.items()}    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obf1cysr2s6e"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/train_padded', 'rb') as f:\n",
        "    train_padded = pickle.load(f)\n",
        "    \n",
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/test_padded', 'rb') as f:\n",
        "    test_padded = pickle.load(f)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyQOLdEA2w7O"
      },
      "source": [
        "**IG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6gVnQ9s0IF1",
        "outputId": "394300bc-2193-4aff-a5fc-33f1db79a11f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f5814f346d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "layer = model_lstm.layers[1]\n",
        "layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBZ70fAY0IF2"
      },
      "outputs": [],
      "source": [
        "n_steps = 50\n",
        "method = \"gausslegendre\"\n",
        "internal_batch_size = 100\n",
        "nb_samples = 20\n",
        "ig  = IntegratedGradients(model_lstm,\n",
        "                          layer=layer,\n",
        "                          n_steps=n_steps,\n",
        "                          method=method,\n",
        "                          internal_batch_size=internal_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to remove UNK\n",
        "\n",
        "def func_remove_unk(b):\n",
        "  l = list(filter(lambda x: x[0] != 'UNK', b))\n",
        "  return l"
      ],
      "metadata": {
        "id": "cVPBPsCpHwxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func_sum (sample):\n",
        "  x = sample\n",
        "  d = {}\n",
        "  [d.__setitem__(first, d.get(first, 0) + second) for first, second in x]\n",
        "  r = list(d.items())\n",
        "  return r"
      ],
      "metadata": {
        "id": "hu_1LHj2b-yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func (val):\n",
        "  x_test = test_padded \n",
        "  j = val\n",
        "  x_test_sample = x_test[j:j+2] #2476\n",
        "  predictions = np.round( model_lstm(x_test_sample).numpy())\n",
        "  explanation = ig.explain(x_test_sample,\n",
        "                         baselines=None,\n",
        "                         target=predictions)\n",
        "\n",
        "  attrs = explanation.attributions[0]\n",
        "  attrs = attrs.sum(axis=2)\n",
        "  #Get attributions values from the explanation object\n",
        "\n",
        "\n",
        "  i = 0\n",
        "  x_i = x_test_sample[i]\n",
        "  attrs_i = attrs[i]\n",
        "  words = decode_sentence(x_i, reverse_index).split()\n",
        "\n",
        "\n",
        "  a=words\n",
        "  b=attrs_i\n",
        "\n",
        "  temp_list = []\n",
        "  for i in range(0, len(a)):\n",
        "    temp_list.append((a[i],b[i]))\n",
        "    l = list(filter(lambda x: x[0] != 'UNK', temp_list))\n",
        "    l = func_sum (l)\n",
        "  sorted_list = sorted(l, key=lambda x: x[1])\n",
        "  return predictions[0], sorted_list"
      ],
      "metadata": {
        "id": "E1HvNcabGZHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_i = pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/positive_sample_50', 'rb'))\n",
        "neg_i = pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/negative_sample_50', 'rb')) "
      ],
      "metadata": {
        "id": "0NyZ6xYlHAPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resN=[]\n",
        "for el in neg_i:\n",
        "  r = func (el)\n",
        "  resN.append(r)"
      ],
      "metadata": {
        "id": "v0Nxh7tQHEpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/ig_cnn_final_list_neg', 'wb') as f:\n",
        "    pickle.dump(resN, f)    "
      ],
      "metadata": {
        "id": "LdhUwhTRHVW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resP=[]\n",
        "for el in pos_i:\n",
        "  r = func (el)\n",
        "  resP.append(r)"
      ],
      "metadata": {
        "id": "GUEcAENKHEr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/ig_cnn_final_list_pos', 'wb') as f:\n",
        "    pickle.dump(resP, f)    "
      ],
      "metadata": {
        "id": "WJu3R9u5HEy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get attributions values from the explanation object\n",
        "i = 0\n",
        "x_i = x_test_sample[i]\n",
        "attrs_i = attrs[i]\n",
        "words = decode_sentence(x_i, reverse_index).split()\n",
        "\n",
        "\n",
        "a=words\n",
        "b=attrs_i\n",
        "\n",
        "temp_list = []\n",
        "for i in range(0, len(a)):\n",
        "  temp_list.append((a[i],b[i]))\n",
        "sorted_list = sorted(temp_list, key=lambda x: x[1])\n",
        "sorted_list"
      ],
      "metadata": {
        "id": "lSh-SrfSFKYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl42REQT3CNn"
      },
      "outputs": [],
      "source": [
        "#predictions =  np.concatenate( predictions, axis=0 )\n",
        "#predictions[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhqsQZHZ0IF3"
      },
      "outputs": [],
      "source": [
        "# Metadata from the explanation object\n",
        "#explanation.meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2r62VJr0IF3"
      },
      "outputs": [],
      "source": [
        "# Data fields from the explanation object\n",
        "#explanation.data.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIOdeO0E0IF3"
      },
      "outputs": [],
      "source": [
        "#Get attributions values from the explanation object\n",
        "attrs = explanation.attributions[0]\n",
        "print('Attributions shape:', attrs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4VdSupr0IF3"
      },
      "outputs": [],
      "source": [
        "attrs = attrs.sum(axis=2)\n",
        "print('Attributions shape:', attrs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfXcbhFm0IF4"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "x_i = x_test_sample[i]\n",
        "attrs_i = attrs[i]\n",
        "pred = predictions[i]\n",
        "pred_dict = {1: 'Positive review', 0: 'Negative review'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJsoYPR70IF4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "def  hlstr(string, color='white'):\n",
        "    \"\"\"\n",
        "    Return HTML markup highlighting text with the desired color.\n",
        "    \"\"\"\n",
        "    return f\"<mark style=background-color:{color}>{string} </mark>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIvNOHNL0IF4"
      },
      "outputs": [],
      "source": [
        "def colorize(attrs, cmap='PiYG'):\n",
        "    \"\"\"\n",
        "    Compute hex colors based on the attributions for a single instance.\n",
        "    Uses a diverging colorscale by default and normalizes and scales\n",
        "    the colormap so that colors are consistent with the attributions.\n",
        "    \"\"\"\n",
        "    import matplotlib as mpl\n",
        "    cmap_bound = np.abs(attrs).max()\n",
        "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
        "    cmap = mpl.cm.get_cmap(cmap)\n",
        "\n",
        "    # now compute hex values of colors\n",
        "    colors = list(map(lambda x: mpl.colors.rgb2hex(cmap(norm(x))), attrs))\n",
        "    return colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vKTwDTL0IF5"
      },
      "outputs": [],
      "source": [
        "words = decode_sentence(x_i, reverse_index).split()\n",
        "colors = colorize(attrs_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkOPsS420IF5"
      },
      "outputs": [],
      "source": [
        "print('Predicted label =  {}: {}'.format(pred, pred_dict[pred]))\n",
        "HTML(\"\".join(list(map(hlstr, words, colors))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny8Aq5Zf0IF6"
      },
      "outputs": [],
      "source": [
        "attrs_i "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64a5ED6KDtRF"
      },
      "outputs": [],
      "source": [
        "#ig values calculated for all test sample\n",
        "x_test = test_padded\n",
        "x_test_sample = x_test\n",
        "predictions = np.round( model_lstm(x_test_sample).numpy())\n",
        "explanation = ig.explain(x_test_sample,\n",
        "                         baselines=None,\n",
        "                         target=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1iJrBzpDtTw"
      },
      "outputs": [],
      "source": [
        "attrs = explanation.attributions[0]\n",
        "attrs = attrs.sum(axis=2)\n",
        "\n",
        "\n",
        "#we need this information to use later for the survey\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/ig_values_lstm', 'wb') as f:\n",
        "  pickle.dump(attrs, f)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmW8OSoaF1Tb"
      },
      "source": [
        "**Sample calculation**\n",
        "\n",
        "Calculating and saving feature importance score for the reviews used as a demonstration example to measure the proposed criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZSo1le0Ge98"
      },
      "outputs": [],
      "source": [
        "pos_sample = pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/positive_sample_50', 'rb'))\n",
        "neg_sample = pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/negative_sample_50', 'rb')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTrBVMmHDtW1"
      },
      "outputs": [],
      "source": [
        "r_ig= pickle.load(open('/content/drive/MyDrive/MasterThesis/Dataset/ig_values_lstm', 'rb'))  \n",
        "r_ig[0]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz9Hcy1MHlt6"
      },
      "outputs": [],
      "source": [
        "#function to remove UNK\n",
        "\n",
        "def func_remove_unk(b):\n",
        "  l = list(filter(lambda x: x[0] != 'UNK', b))\n",
        "  return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lreWoja-ECYp"
      },
      "outputs": [],
      "source": [
        "#match each word with its value\n",
        "def match_words(vec): #vec = list of indexes\n",
        "  ig_values = []\n",
        "  for i in vec:\n",
        "    temp = []\n",
        "    x_i = test_padded[i]\n",
        "    attrs_i = r_ig[i]\n",
        "    words = decode_sentence(x_i, reverse_index).split()\n",
        "    for indx in range(len(words)):\n",
        "      temp.append((words[indx], attrs_i[indx]))\n",
        "    ig_values.append(temp)\n",
        "  return ig_values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = pos_sample[0]\n",
        "test_padded[i]\n",
        "r_ig[i]\n",
        "decode_sentence(x_i, reverse_index).split()\n",
        "i"
      ],
      "metadata": {
        "id": "n0i5873HD5x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNQBvAOrECdp"
      },
      "outputs": [],
      "source": [
        "p = match_words(pos_sample)\n",
        "n = match_words(neg_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0l7tBcfDtZM"
      },
      "outputs": [],
      "source": [
        "def func_sum (sample):\n",
        "  my_sum = []\n",
        "  for i in range(len(sample)):\n",
        "    x = sample[i]\n",
        "    d = {}\n",
        "    [d.__setitem__(first, d.get(first, 0) + second) for first, second in x]\n",
        "    r = list(d.items())\n",
        "    my_sum.append(r)\n",
        "  return my_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8ck0vymDtbc"
      },
      "outputs": [],
      "source": [
        "resp = func_sum(p)\n",
        "resn = func_sum(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c4Sj1KHHJXC"
      },
      "outputs": [],
      "source": [
        "r1 = []\n",
        "for el in resp:\n",
        "  a = func_remove_unk(el)\n",
        "  a_sorted = sorted(a, key=lambda x: x[1])\n",
        "  r1.append(a_sorted)\n",
        "\n",
        "r2 = []\n",
        "for el in resn:\n",
        "  a = func_remove_unk(el)\n",
        "  a_sorted = sorted(a, key=lambda x: x[1])\n",
        "  r2.append(a_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93VoPowYDtgb"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/ig_lstm_final_list_pos', 'wb') as f:\n",
        "    pickle.dump(r1, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/ig_lstm_final_list_neg', 'wb') as f:\n",
        "    pickle.dump(r2, f)     "
      ]
    }
  ],
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "lstm_IG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}