{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERTForSequenceClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference for this notebook: [Fine Tunning Bert For Sentiment Analysis](https://skimai.com/fine-tuning-bert-for-sentiment-analysis/)"
      ],
      "metadata": {
        "id": "vVrFdmRPZxSg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM3KWuRB8Fq0",
        "outputId": "db3662b2-08a4-4d88-bed5-833912c780d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY9JCny0_aQg"
      },
      "source": [
        "pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIDt_6DvLcoq",
        "outputId": "85b9c383-516f-47c7-bda1-512067d19f04"
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "import sklearn.metrics as metrics\n",
        "import pickle\n",
        "from torch.utils.data import TensorDataset, random_split #creating tensor datasets and DataLoaders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRm_sXWu98Te"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO7q5KXu98o2",
        "outputId": "526e61e2-be3e-4f6f-f4e2-ab1c28557c0a"
      },
      "source": [
        "#we add GPU so the code can run faster\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_UId0NV-BUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da66de4-984d-4607-c6e5-f28e9b8e19fc"
      },
      "source": [
        "import torch\n",
        "\n",
        "#GPU is available\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# GPU not available\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9PAEtAh_Rkx",
        "outputId": "c5e08bf7-4f06-42a8-d9d8-bbe0902fc845"
      },
      "source": [
        "#BERT tokenizer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5g8y9qEKCrR"
      },
      "source": [
        "**PART 1 - One Time Run**\n",
        "\n",
        "Dataset is transform and saved as input for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHN8Lxmx-QJo"
      },
      "source": [
        "**Read the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty9aXsv_-D-1"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_train_all.csv')\n",
        "test =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_test_all.csv')\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/y_train_all.csv')\n",
        "y_test =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/y_test_all.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a column with words length 50 to be used because bert will lematize the words itsel\n",
        "#and we should make sure it is using all the same words\n",
        "\n",
        "train['pad_50_sen'] = train['clean_review'].astype(str).apply(lambda x : ' '.join(x.strip().split(\" \")[:50]))\n",
        "test['pad_50_sen'] = test['clean_review'].apply(lambda x : ' '.join(x.strip().split(\" \")[:50]))"
      ],
      "metadata": {
        "id": "7Cw_0R_sTOou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMO1ICG3-aX0"
      },
      "source": [
        "#in order to have the same training test as other neural networks, we get the validation set from train_df\n",
        "train, val, y_train, y_val = train_test_split(train, y_train, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK7MPuQG-_Fu"
      },
      "source": [
        "# Get the lists of reviews and their labels.\n",
        "#we use the reviews which are cutted to the number of 50 words\n",
        "#so we make sure that all classfiers are trained and tested using the same sentences\n",
        "train_x = train.pad_50_sen.values\n",
        "train_y = y_train.rate.values\n",
        "\n",
        "val_x = val.pad_50_sen.values\n",
        "val_y = y_val.rate.values\n",
        "\n",
        "test_x = test.pad_50_sen.values\n",
        "test_y = y_test.rate.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPfdEiqkLvM4"
      },
      "source": [
        "**Transform the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xACR1Lze_Y53"
      },
      "source": [
        "#SENTENCE TOKENIZATION\n",
        "def get_inputs_ids_mask(reviews, labels):\n",
        "  %%time\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in reviews:\n",
        "      # `encode_plus will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the [CLS] token to the start.\n",
        "      #   (3) Append the [SEP] token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 100, #we set the max length to 100 considering that bert applies word-piece tokenization\n",
        "                          padding = 'max_length',\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                          truncation = True\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFlUWMRQLFWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac19356-5f62-4c09-ec72-9d545c2d475d"
      },
      "source": [
        "train_ii, train_masks, train_labels = get_inputs_ids_mask(train_x, train_y)\n",
        "val_ii, val_masks, val_labels = get_inputs_ids_mask(val_x, val_y)\n",
        "test_ii, test_masks, test_labels = get_inputs_ids_mask(test_x, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 6.68 µs\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.01 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qm0XZ9TMQ_n"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(train_ii, train_masks, train_labels)\n",
        "val_dataset = TensorDataset(val_ii, val_masks, val_labels)\n",
        "test_dataset = TensorDataset(test_ii, test_masks, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j9_mDLINGnZ"
      },
      "source": [
        "# Save the tensorDatasets: --test dataset will be needed later for prediction part\n",
        "torch.save(train_dataset, '/content/drive/MyDrive/MasterThesis/Dataset/train_tensor_ds')\n",
        "torch.save(val_dataset, '/content/drive/MyDrive/MasterThesis/Dataset/val_tensor_ds')\n",
        "torch.save(test_dataset, '/content/drive/MyDrive/MasterThesis/Dataset/test_tensor_ds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ49QZkQKsxB"
      },
      "source": [
        "**PART 2 - Train and save the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6h05YItI5qB"
      },
      "source": [
        "#load tensor datset\n",
        "train_dataset = torch.load('/content/drive/MyDrive/MasterThesis/Dataset/train_tensor_ds')\n",
        "val_dataset = torch.load('/content/drive/MyDrive/MasterThesis/Dataset/val_tensor_ds')\n",
        "test_dataset = torch.load('/content/drive/MyDrive/MasterThesis/Dataset/test_tensor_ds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdvkKC_6NfAg"
      },
      "source": [
        "#an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory.\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Specifying batch size for the DataLoader\n",
        "# The the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training set\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "# Create the DataLoaders for our validation set\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w84h456UNuGK"
      },
      "source": [
        "**Initializing BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RXUDgvNpvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a346fc-a735-4575-8735-6b435d172e47"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # 12-layer BERT model with an uncased vocab.\n",
        "    num_labels = 2, # we have two classes: positive and negative  \n",
        "    output_attentions = False, # return attentions weights.\n",
        "    output_hidden_states = False, # return hidden-states.\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4hR8XkzTE2y"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyLCTDk2TpXv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "# authors recommend between 2 and 4. \n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps = [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb5NRhZ9WV49"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyomvPOHWYjv"
      },
      "source": [
        "#Helper function for formatting elapsed times as hh:mm:ss\n",
        "import datetime\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xNNlpymWavj"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEnPCf_daURN"
      },
      "source": [
        "**Training and Save the Model - One Time Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WquFH7bOWcPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ba954b-ed1e-46b6-eb49-67ff4f7bcba3"
      },
      "source": [
        "#TRAINING\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. \n",
        "        model.zero_grad()        \n",
        "         \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "        loss_logits_ = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask, \n",
        "                            labels=b_labels)\n",
        "\n",
        "        loss = loss_logits_[0]\n",
        "        logits_t = loss_logits_[1]\n",
        "\n",
        "        logits_t_cpu = logits_t.detach().cpu().numpy()\n",
        "        train_pred = np.argmax(logits_t_cpu, axis=1).flatten()\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            loss_logits = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = loss_logits[0]\n",
        "            logits_val = loss_logits[1]\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits_val = logits_val.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        val_pred = np.argmax(logits_val, axis=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits_val, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    460.    Elapsed: 0:00:20.\n",
            "  Batch    80  of    460.    Elapsed: 0:00:40.\n",
            "  Batch   120  of    460.    Elapsed: 0:01:00.\n",
            "  Batch   160  of    460.    Elapsed: 0:01:20.\n",
            "  Batch   200  of    460.    Elapsed: 0:01:41.\n",
            "  Batch   240  of    460.    Elapsed: 0:02:02.\n",
            "  Batch   280  of    460.    Elapsed: 0:02:23.\n",
            "  Batch   320  of    460.    Elapsed: 0:02:44.\n",
            "  Batch   360  of    460.    Elapsed: 0:03:05.\n",
            "  Batch   400  of    460.    Elapsed: 0:03:27.\n",
            "  Batch   440  of    460.    Elapsed: 0:03:48.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epcoh took: 0:03:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation Loss: 0.21\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    460.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    460.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    460.    Elapsed: 0:01:04.\n",
            "  Batch   160  of    460.    Elapsed: 0:01:25.\n",
            "  Batch   200  of    460.    Elapsed: 0:01:46.\n",
            "  Batch   240  of    460.    Elapsed: 0:02:08.\n",
            "  Batch   280  of    460.    Elapsed: 0:02:29.\n",
            "  Batch   320  of    460.    Elapsed: 0:02:51.\n",
            "  Batch   360  of    460.    Elapsed: 0:03:12.\n",
            "  Batch   400  of    460.    Elapsed: 0:03:33.\n",
            "  Batch   440  of    460.    Elapsed: 0:03:55.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:04:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.23\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    460.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    460.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    460.    Elapsed: 0:01:03.\n",
            "  Batch   160  of    460.    Elapsed: 0:01:25.\n",
            "  Batch   200  of    460.    Elapsed: 0:01:46.\n",
            "  Batch   240  of    460.    Elapsed: 0:02:07.\n",
            "  Batch   280  of    460.    Elapsed: 0:02:28.\n",
            "  Batch   320  of    460.    Elapsed: 0:02:50.\n",
            "  Batch   360  of    460.    Elapsed: 0:03:11.\n",
            "  Batch   400  of    460.    Elapsed: 0:03:32.\n",
            "  Batch   440  of    460.    Elapsed: 0:03:53.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:04:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.29\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:12:36 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlfmQ_c0Wd5o"
      },
      "source": [
        "#Saving the model\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/MasterThesis/Dataset/tokenizer_bert_1')\n",
        "torch.save(model, '/content/drive/MyDrive/MasterThesis/BERT/bert_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sin1LRU7Z9Jj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "a2b054b5-5164-4a50-b7da-4f95bcabd869"
      },
      "source": [
        "#Summary of training process\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cc2f7145-53c7-4212-88dd-19d27fc566b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0:03:58</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.16</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:04:05</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.09</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0:04:03</td>\n",
              "      <td>0:00:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc2f7145-53c7-4212-88dd-19d27fc566b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc2f7145-53c7-4212-88dd-19d27fc566b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc2f7145-53c7-4212-88dd-19d27fc566b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.28         0.21           0.91       0:03:58         0:00:10\n",
              "2               0.16         0.23           0.92       0:04:05         0:00:10\n",
              "3               0.09         0.29           0.92       0:04:03         0:00:10"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3fe5zNSaMyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c976237-e861-4238-f58c-ef40876eb656"
      },
      "source": [
        "df_stats[['Training Loss', 'Valid. Loss', 'Valid. Accur.']].mean().apply(lambda x: round(x, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Training Loss    0.18\n",
              "Valid. Loss      0.24\n",
              "Valid. Accur.    0.92\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvKgjB0DaY9s"
      },
      "source": [
        "**Part 3 - Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWBEjwhyaa06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d24fe0-8db6-4fdb-dda0-bbe54390d2b8"
      },
      "source": [
        "#Initializing the model\n",
        "from transformers import BertTokenizer\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "device = torch.device(\"cuda\")\n",
        "model = torch.load('/content/drive/MyDrive/MasterThesis/BERT/bert_1', map_location=\"cuda:0\")  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "# Make sure to call input = input.to(device) on any input tensors that you feed to the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_TUCPCZYzzV"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "# Save the tensorDatasets\n",
        "test_dataset = torch.load('/content/drive/MyDrive/MasterThesis/Dataset/test_tensor_ds')\n",
        "\n",
        "prediction_sampler = SequentialSampler(test_dataset)\n",
        "prediction_dataloader = DataLoader(test_dataset, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk3O95vramkr"
      },
      "source": [
        "#accuracy for testing\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S5xwpH3Ynkl"
      },
      "source": [
        "from torch.nn import functional as F\n",
        "# a function tu evaluate a model\n",
        "def evaluate_model(model, dataloader, GPU_device):\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "  \n",
        "  # Tracking variables \n",
        "  predictions, true_labels = [], []\n",
        "\n",
        "  # Predict \n",
        "  for batch in dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits= logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "  \n",
        "\n",
        "  loss_cross = F.cross_entropy(outputs.logits, b_labels)\n",
        "  print('loss is: ' + str(loss_cross))\n",
        "  print('    DONE.')\n",
        "  return predictions, true_labels, loss_cross"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUvnBd9xYpG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8252d82-2d4d-466a-f198-0833cbad6add"
      },
      "source": [
        "#we can create a train_dataloader too and check the results, but I do not thin it is neccessary right now\n",
        "pred_test, true_test, loss_test = evaluate_model(model, prediction_dataloader, device) #as logit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss is: tensor(0.3192, device='cuda:0')\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq9qboHLjA_U"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQldraDSZB04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce68b4fb-df0b-474d-9550-1c0643e76002"
      },
      "source": [
        "#test\n",
        "total_eval_accuracy = 0\n",
        "for i in range(len(pred_test)):\n",
        "  total_eval_accuracy += flat_accuracy(pred_test[i], true_test[i])\n",
        "#print(total_eval_accuracy)\n",
        "#test\n",
        "avg_val_accuracy = total_eval_accuracy / len(prediction_dataloader)\n",
        "print(\"Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "#test\n",
        "pred_flat = np.argmax(pred_test[0], axis=1).flatten()\n",
        "labels_flat = true_test[0].flatten()\n",
        "tot_ev_acc = np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "#print(tot_ev_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjH-PtFSaIoL"
      },
      "source": [
        "#flat predictions\n",
        "import itertools\n",
        "test =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_test_all.csv')\n",
        "y_pred =   []\n",
        "for review in test.clean_review:\n",
        "  encoded = tokenizer.encode_plus(str(review), return_token_type_ids=False, return_tensors = 'pt', truncation = True)\n",
        "  encoded_ids = encoded['input_ids'].to(device)\n",
        "  enconded_attention = encoded['attention_mask'].to(device)\n",
        "  with torch.no_grad(): \n",
        "    output = model(encoded_ids, attention_mask=enconded_attention)[0]\n",
        "    output = output.detach().cpu().numpy()\n",
        "    pred_flat = np.argmax(output, axis=1).flatten()\n",
        "    y_pred.append(pred_flat)\n",
        "    \n",
        "y_pred = (list(itertools.chain.from_iterable(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmyYCLU0cfI9"
      },
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/bert_1_pred', 'wb') as f:\n",
        "    pickle.dump(y_pred, f)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRxlMnrYfHuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1babfab5-88ea-4d8b-f3d6-b7a79a424f4f"
      },
      "source": [
        "y_test = (pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/y_test_all.csv')).rate\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sn.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
        "            fmt='.2%', cmap='Blues')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff7e6b63bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh6Q3ANmgMRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654023b1-8749-4807-a2a3-1cf4ef9fb2a1"
      },
      "source": [
        "print (metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      2038\n",
            "           1       0.94      0.94      0.94      2045\n",
            "\n",
            "    accuracy                           0.94      4083\n",
            "   macro avg       0.94      0.94      0.94      4083\n",
            "weighted avg       0.94      0.94      0.94      4083\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions as propabilities\n",
        "import itertools\n",
        "test =  pd.read_csv('/content/drive/MyDrive/MasterThesis/Dataset/X_test_all.csv')\n",
        "y_pred =   []\n",
        "for review in test.clean_review:\n",
        "  encoded = tokenizer.encode_plus(str(review), return_token_type_ids=False, return_tensors = 'pt', truncation = True)\n",
        "  encoded_ids = encoded['input_ids'].to(device)\n",
        "  enconded_attention = encoded['attention_mask'].to(device)\n",
        "  with torch.no_grad(): \n",
        "    output = model(encoded_ids, attention_mask=enconded_attention)[0]\n",
        "    tensor_logits = output\n",
        "    probas = F.softmax(tensor_logits, dim=-1).cpu().detach().numpy()\n",
        "    y_pred.append(probas)\n",
        "    \n",
        "y_pred = (list(itertools.chain.from_iterable(y_pred)))"
      ],
      "metadata": {
        "id": "729-D8p6WUCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/MasterThesis/Dataset/bert_1_pred_propab', 'wb') as f:\n",
        "    pickle.dump(y_pred, f)    "
      ],
      "metadata": {
        "id": "a0ad7i4sov6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}